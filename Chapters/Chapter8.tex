\chapter{Eigenvalues and Eigenvectors}
Consider a vector space $V$ and a linear mapping $A:V\to V$
\begin{definition}
A vector $\vv\in V$, $\vv\not=0$ is called an eigenvector of $A$, if there exists scalar $\lambda$, such that $A\vv = \lambda\vv$. This scalar $\lambda$ is called an eigenvalue, corresponding to eigenvector $\vv$.\\

Sometimes, eigenvectors are called characetristic vectors, and eigenvalues are called characteristic values. 
\end{definition}

\begin{example}
Consider
\[
A\in\R^{n,n} = \begin{pmatrix}
a_{11} & \dots & 0\\
\vdots & \ddots & \vdots\\
0 & \dots & a_{nn}
\end{pmatrix}
\]	
Then 
\[
E_i = \colvec{3}{0}{\vdots}{0}-i
\]
is an eigenvector with eigenvalue $a_{ii}$, because
\[
AE_i = a_{ii}E_i
\]
\end{example}
\begin{lemma}
Consider $A:V\to V$ and $\vv\not=0$. An eigenvector with $\lambda$ - eigenvalue. Then, for any scalar $\alpha\not=0$, $(\alpha\lambda)$ is also an eigenvector with the same eigenvalue $\lambda$
\end{lemma}
\begin{proof}
\begin{align*}
A\vv &= \lambda\vv\\
A(\alpha\vv)&=\alpha(\lambda\vv) = \lambda(\alpha\vv)
\end{align*}
\end{proof}

\begin{theorem}
Consider the linear mapping $A:V\to V$ and eigenvalue $\lambda$. Assume that there exists $v_1,\dots,v_n$ eigenvectors corresponding to the eigenvalue. THen any vector from the span of $v_1,\dots,v_n$ (any linear combination of $v_m,\dots,v_m$) is also an eigenvector of $A$, with the same eigenvalue $\lambda$
\end{theorem}

\begin{proof}
Take any linear combination of $v_1,\dots,v_m$
\begin{align*}
&\alpha_1 v_1 + \dots + \alpha_m v_m\\
& A(\alpha_1 v_1 + \dots + \alpha_m v_m) = \alpha_1 A v_1 + \dots + \alpha_m A v_m\\
=& \alpha_1 \lambda v_1 + \dots + \alpha_m \lambda v_m = \lambda ( \alpha_1 v_1 + \dots + \alpha_m v_m)\\
\Rightarrow & \alpha_1 v_1 + \dots + \alpha_m v_m \Rightarrow \text{ is indeed an eigenvector with eigenvalue }\lambda
\end{align*}
\end{proof}

\begin{remark}
It means that the span of $v_1,\dots,v_m$ forms a subspace in $V$ and any non - zero vector from this subspace is an eigenvector of $A$ with eigenvalue $\lambda$\\

This subspace is called an eigenspace of $A$ with eigenvalue $\lambda$	
\end{remark}

\begin{theorem}
Consider $A:V\to V$ - linear mapping. Assume that there exists eigenvectors $v_1,\dots,v_m$ with corresponding eigenvalues $\lambda_1,\dots,\lambda_m$. Let us also assume that all eigenvalues are distinct, $\lambda_i \not=\lambda_j$ for $i\not= j$. Then $v_1,\dots,v_m$ are linearly independent
\end{theorem}

\begin{proof}
By induction on $m$.
\begin{itemize}
\item $m = 1$: \\
$v_i$ - eigenvector, $\lambda_1$ - eigenvalue. By definition, $v_1\not=0$, therefore $v_1$ is linearly independent. 

\item $m>1$:\\
Assume that the theorem holds for any $n-1$ eigenvector and eigenvalue. Let us assume $v_1,\dots,v_m$ are linearly dependent. 
\[
\alpha_1 v_1 + \dots + \alpha_m v_m\hspace{5mm}(\ast)
\]
Let us multiply $(\ast)$ by $\lambda_m$:
\[
\alpha_1 \lambda_m v_1 + \dots + \alpha_m \lambda_m v_m = 0
\]
let us apply $A$ to $(\ast)$:
\begin{align*}
A(\alpha_1 v_1 + \dots + \alpha_m v_m) &= \alpha_1 A v_1 + \dots + \alpha_m A v_m\\
&= \alpha_1 \lambda_1 v_1 + \dots + \alpha_m\lambda_m v_m = 0
\end{align*}
Subtract $1^{st}$ from $2^{nd}$:
\[
\alpha_1(\lambda_1 - \lambda_m)v_1+\dots+\alpha_{m-1}(\lambda_{m-1} - \lambda_{m-1})v_{m-1} = 0
\]
(There are ${m-1}$ eigenvectors)
\begin{enumerate}
\item[$\Rightarrow$] They are linearly independent by the induction hypothesis
\item[$\Rightarrow$] $\alpha_1 \underbrace{(\lambda_1-\lambda_m)}_{\not=0} = 0, \dots,\alpha_{m-1} \underbrace{(\lambda_{m-1}-\lambda_m)}_{\not=0} = 0$\\

Since $\lambda_i\not=\lambda_j\Rightarrow \alpha_1=0,\dots,\alpha_{m-1} = 0$ and then from $(\ast)\Rightarrow\alpha_m = 0$, since $\vv_m \not=0$
\item[$\Rightarrow$] $v_1,\dots,v_m$ are linearly independent 
\end{enumerate}
\end{itemize}
\end{proof}

\begin{remark}
If $A:V\to V$ is a linear mapping and $V$ is a $n-$ dimensional space. If we have $v_1,\dots,v_n$	 eigenvectors of $A$ with all distinct $\lambda_1,\dots,\lambda_n$, then $v_1,\dots,v_n$ from a basis of $V$.
\end{remark}

\section{Characteristic Polynomial}
How to find eigenvalues and eigenvectors?
\subsubsection*{Recall}
\begin{enumerate}
\item Let us consider the linear mapping $A:V\to V$. $A$ is invertible $\Leftrightarrow$ the nullspace of $A$ is $\{ \ul{0}\}$
\[
N(A) = \{ \ul{x}\in V, A\ul{x} = \ul{0} \}
\]
\item $A$ is invertible $\Leftrightarrow\det(A)\not=0$
\end{enumerate}
\begin{theorem}
Let us consider $A\in\R^{n,n}$. $\lambda$ is an eigenvalue of $A$ iff $(\lambda I - A)$ is not invertible.
\end{theorem}
\begin{proof}
$\lambda$ is an eigenvalue of $A$, $\exists \vv\not = \ul{0}$ such that 
\[
A\vv = \lambda\vv \Rightarrow -\lambda\vv + A\vv = -(\lambda I - A)\vv =0
\]
therefore $\lambda I -A$ has a non - zero vector $\vv$ in its null space, and thanks to 1. $\lambda I -A$  is not invertible
\end{proof}
\begin{definition}
Consider $A\in\R^{n,n}$. The characteristic polynomial is defined as 
\[
p_a(t) = \det( t I - A)
\]
\end{definition}
\begin{example}
\[
A = \begin{pmatrix}
1 & 0 & 2\\
0 & 1 & 1\\
1 & 0 & 1
\end{pmatrix}, p_a(t) = ?
\]
\begin{align*}
p_a(t) &= \abs{\begin{pmatrix}
t-1 & 0 & 2\\
0 & t-1 & 1\\
1 & 0 & t-1
\end{pmatrix}}\\
&= (t-1)^3 - 2(t-1) \\
&= (t-1)((t-1)^2-2) \\
&= (t-1)(t^2-2t-1)
\end{align*}
\end{example}

\begin{theorem}
Consider $A\in\R^{n,n}$. $\lambda$ is an eigenvalue of $A$ iff $\lambda$ is a root of the characteristic polynomial $p_a(t)$
\end{theorem}
\begin{proof}
\begin{enumerate}
\item[$\Rightarrow$:] $\lambda$ is an eigenvalue of $A$. Then from previous theorem $(\lambda I -A) $ is non invertible. \\ $\det(\lambda I - A) = 0$ but $ \det(\lambda I - A) = p_a(t=\lambda)\Rightarrow\lambda$ is a root of $p_a(t)$
\item[$\Leftarrow$:] if $\lambda$ is a root of $p_a(t)$, then $p_a(\lambda ) = \det(\lambda I - A) = 0$\\ $\lambda I - A$ is not invertible, from previous theorem. $\lambda$ is an eigenvalue.
\end{enumerate}
\end{proof}
\begin{example}
Consider 
\[
A = \begin{pmatrix}
1 & 4\\
2 & 3
\end{pmatrix}
\]	
find the Eigenvalues and Eigenvectors. 
\begin{align*}
p_a(t) = \det(tI-A) = \left|\begin{matrix}
t-1 & -4\\
-2 & t-3
\end{matrix}
 \right| &= (t-1)(t-3)-8\\
&= t^2-4t-5\\
&= (t+1)(t-5) 
\end{align*}
The two roots of $p_a(t)$ are $\lambda_1 = -1, \lambda_2 = 5$, which are also the eigenvalues. We can now find the eigenvector for $\lambda_1 = -1$:
\begin{align*}
\begin{pmatrix}
1 & 4\\
2 & 3
\end{pmatrix}\begin{pmatrix}
v_1\\
v_2
\end{pmatrix} = -1\cdot\begin{pmatrix}
v_1\\
v_2
\end{pmatrix} \Rightarrow &\begin{rightalignedcases}
v_1 + 4v_2 = -v_1\\
2v_1 + 3v_2 = -v_2
\end{rightalignedcases}\\
\Rightarrow &\begin{rightalignedcases}
2v_1 + 4v_2 = 0\\
2v_1 + 4v_2 = 0
\end{rightalignedcases}\\
\Rightarrow &\begin{rightalignedcases}
v_1 + 2v_2 = 0\\
0 = 0
\end{rightalignedcases}\\
\Rightarrow & v_1 = 1, v_2 = -\frac{1}{2}\\
\Rightarrow &\text{ Eigenvector is }\colvec{2}{1}{-\frac{1}{2}}
\end{align*}
and the eigenvector for $\lambda_2 = 5$:
\begin{align*}
\begin{pmatrix}
1 & 4\\
2 & 3
\end{pmatrix}\begin{pmatrix}
v_1\\
v_2
\end{pmatrix} = 5\cdot\begin{pmatrix}
v_1\\
v_2
\end{pmatrix} \Rightarrow &\begin{rightalignedcases}
-4v_1 + 4v_2 = 0\\
2v_1 -2v_2 = 0
\end{rightalignedcases}\\
\Rightarrow &\begin{rightalignedcases}
-v_1 + v_2 = 0\\
0 = 0
\end{rightalignedcases}\\
\Rightarrow & v_1 = 1, v_2 = 1\\
\Rightarrow &\text{ Eigenvector is }\colvec{2}{1}{1}
\end{align*}
\end{example}

\begin{example}
Consider
\[
A = \begin{pmatrix}
2 & 1 & 0\\
0 & 1 & -1\\
0 & 2 & 4	
\end{pmatrix}
\]	What are the eigenvalues and eigenvectors?
\[
p_a(t) = \det(tI-A) = \left| \begin{matrix}
t-2 & -1 & 0\\
0 & t-1 & 1\\
0 & -2 & t-4
\end{matrix}
\right| = (t-2)^2(t-3)
\]
Then the eigenvalues are $\lambda_1 = 3,\lambda_2 = 2,\lambda_3 = 2$. Eigenvector for $\lambda_1 = 3$:
\begin{align*}
A\ul{x} = \lambda_1 \ul{x}\Rightarrow &\begin{rightalignedcases}
2x_1+x_2 = 3x_1\\
x_2-x_3 = 3x_2\\
2x_2+4x_3 = 3x_3
\end{rightalignedcases}\\
\Rightarrow &\begin{rightalignedcases}
-x_1+x_2 = 0\\
-2x_2-x_3=0\\
2x_2+x_3=0
\end{rightalignedcases}\\
\Rightarrow &\begin{rightalignedcases}
-x_1+x_2=0\\
2x_2+x_3=0\\
0 = 0
\end{rightalignedcases}\\
\Rightarrow &\text{ Let us choose }x_1 = 1, \text{ then }x_2 = 1,x_3 = -2\\
\Rightarrow &\colvec{3}{1}{1}{-2}
\end{align*}
Eigenvector for $\lambda_{2,3} = 2$:
\begin{align*}
A\ul{x} = 2 \ul{x}\Rightarrow &\begin{rightalignedcases}
2x_1+x_2 = 2x_1\\
x_2-x_3 = 2x_2\\
2x_2+4x_3 = 2x_3
\end{rightalignedcases}\\
\Rightarrow &\begin{rightalignedcases}
x_2 = 0\\
-x_2-x_3=0\\
2x_2+2x_3=0
\end{rightalignedcases}\\
\Rightarrow &\begin{rightalignedcases}
x_2=0\\
x_3=0\\
0 = 0
\end{rightalignedcases}\\
\Rightarrow &\text{ We can choose }x_1 = 1, \text{ then }x_2 = 0,x_3 = 0\\
\Rightarrow &\colvec{3}{1}{0}{0}
\end{align*}
\end{example}
\begin{example}
Consider
\[
A = \begin{pmatrix}
3 & 0 & 0\\
0 & 2 & 0\\
0 & 0 & 2	
\end{pmatrix}
\]	
What are the eigenvalues and eigenvectors?
\[
p_a(t) = \det(tI-A) = \left| \begin{matrix}
t-3 & 0 & 0\\
0 & t-2 & 0\\
0 & 0 & t-2
\end{matrix}
\right| = (t-2)^2(t-3)
\]
Then the eigenvalues are $\lambda_1 = 3,\lambda_2 = 2,\lambda_3 = 2$. Eigenvector for $\lambda_{2,3} = 2$:
\[
A\ul{x} = 2\ul{x}\Rightarrow \begin{rightalignedcases}
3x_1 = 2x_1\\
2x_2 = 2x_2\\
2x_3 = 2x_3
\end{rightalignedcases}\Rightarrow \begin{rightalignedcases}
x_1 = 0\\
0 = 0\\
0 = 0
\end{rightalignedcases}
\]
We have three equations, one variable is determined ($x_1=0$) and we have two independent variables ($x_2,x_3$) which we can choose arbitrarily. Therefore:
\begin{align*}
x_2 =1,x_3 = 0\Rightarrow &\colvec{3}{0}{1}{0}\\
x_2 =0,x_3 = 1\Rightarrow &\colvec{3}{0}{0}{1}\\
\end{align*}
We can get two linearly independent eigenvectors. Each eigenvalue can have 0 or 1 corresponding eigenvectors. $k-$eigenvalues$\to k$ corresponding eigenvectors at most. 

\end{example}

